{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Wizard Assistant Implementation\n",
    "\n",
    "This notebook demonstrates the implementation of an Email Wizard Assistant using a Retrieval-Augmented Generation (RAG) model. The assistant helps users find answers to their email queries by retrieving relevant past emails and generating intelligent responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install numpy pandas scikit-learn torch transformers sentence-transformers flask faiss-cpu tqdm python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Add the parent directory to sys.path to import from src\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "# Import our custom modules\n",
    "from src.embedding import EmailEmbedder\n",
    "from src.similarity_search import SimilaritySearch\n",
    "from src.response_generator import ResponseGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Email Dataset\n",
    "\n",
    "Let's load our sample email dataset and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the sample emails\n",
    "with open('../data/sample_emails.json', 'r') as f:\n",
    "    emails = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(emails)} emails from the dataset.\")\n",
    "\n",
    "# Display the first email as an example\n",
    "print(\"\\nExample Email:\")\n",
    "example_email = emails[0]\n",
    "for key, value in example_email.items():\n",
    "    if key == 'body':\n",
    "        print(f\"{key}: {value[:100]}...\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze some basic statistics about our email dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "emails_df = pd.DataFrame(emails)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"Email Dataset Statistics:\")\n",
    "print(f\"Number of emails: {len(emails_df)}\")\n",
    "print(f\"Unique senders: {emails_df['sender'].nunique()}\")\n",
    "print(f\"Unique recipients: {emails_df['recipient'].nunique()}\")\n",
    "\n",
    "# Calculate email body lengths\n",
    "emails_df['body_length'] = emails_df['body'].apply(len)\n",
    "print(f\"Average email body length: {emails_df['body_length'].mean():.2f} characters\")\n",
    "print(f\"Min email body length: {emails_df['body_length'].min()} characters\")\n",
    "print(f\"Max email body length: {emails_df['body_length'].max()} characters\")\n",
    "\n",
    "# Plot email body length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(emails_df['body_length'], bins=10, alpha=0.7)\n",
    "plt.title('Email Body Length Distribution')\n",
    "plt.xlabel('Number of Characters')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Email Embedding\n",
    "\n",
    "Now, let's embed our emails using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the email embedder\n",
    "embedder = EmailEmbedder(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "# Check if embeddings already exist\n",
    "try:\n",
    "    embeddings = embedder.load_embeddings('../data/embeddings.pkl')\n",
    "    print(f\"Loaded {len(embeddings)} existing embeddings.\")\n",
    "except Exception as e:\n",
    "    print(f\"No existing embeddings found: {e}\")\n",
    "    embeddings = {}\n",
    "\n",
    "# If no embeddings exist, create them\n",
    "if not embeddings:\n",
    "    print(\"Creating new embeddings...\")\n",
    "    start_time = time.time()\n",
    "    embeddings = embedder.embed_emails(emails)\n",
    "    end_time = time.time()\n",
    "    print(f\"Embedding completed in {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "    # Save the embeddings\n",
    "    embedder.save_embeddings(embeddings, '../data/embeddings.pkl')\n",
    "    print(f\"Saved {len(embeddings)} embeddings to file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the embeddings we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get a sample embedding\n",
    "sample_email_id = list(embeddings.keys())[0]\n",
    "sample_embedding = embeddings[sample_email_id]\n",
    "\n",
    "print(f\"Sample embedding for email ID {sample_email_id}:\")\n",
    "print(f\"Shape: {sample_embedding.shape}\")\n",
    "print(f\"First 10 values: {sample_embedding[:10]}\")\n",
    "\n",
    "# Visualize embedding distribution for the sample\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(sample_embedding, bins=30, alpha=0.7)\n",
    "plt.title('Embedding Value Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(sample_embedding)\n",
    "plt.title('Embedding Vector')\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Similarity Search Implementation\n",
    "\n",
    "Now, let's implement the similarity search functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the similarity search\n",
    "similarity_search = SimilaritySearch(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "# Build the search index\n",
    "similarity_search.build_index(embeddings, emails)\n",
    "print(\"Search index built successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the similarity search with a few example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define some test queries\n",
    "test_queries = [\n",
    "    \"What's the status of our project?\",\n",
    "    \"When is the server maintenance scheduled?\",\n",
    "    \"Tell me about the new benefits enrollment\",\n",
    "    \"What was the feedback from the client presentation?\",\n",
    "    \"Is there a bug in the login page?\"\n",
    "]\n",
    "\n",
    "# Test each query\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    start_time = time.time()\n",
    "    results = similarity_search.search(query, k=3)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Search completed in {(end_time - start_time) * 1000:.2f} ms\")\n",
    "    print(f\"Top {len(results)} results:\")\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i+1}:\")\n",
    "        print(f\"  Email ID: {result['id']}\")\n",
    "        print(f\"  Subject: {result['subject']}\")\n",
    "        print(f\"  Similarity: {result['similarity']:.4f}\")\n",
    "        print(f\"  Snippet: {result['snippet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Response Generation\n",
    "\n",
    "Now, let's implement the response generation using our RAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the response generator\n",
    "response_generator = ResponseGenerator(model_name=\"google/flan-t5-base\")\n",
    "print(\"Response generator initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the response generation with our example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test response generation for each query\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    # Search for relevant emails\n",
    "    results = similarity_search.search(query, k=3)\n",
    "    \n",
    "    # Generate response\n",
    "    start_time = time.time()\n",
    "    response = response_generator.generate_response(results, query)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Response generated in {(end_time - start_time):.2f} seconds\")\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Evaluation\n",
    "\n",
    "Let's evaluate the performance of our Email Wizard Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a larger set of test queries for performance evaluation\n",
    "evaluation_queries = [\n",
    "    \"What's the status of our project?\",\n",
    "    \"When is the server maintenance scheduled?\",\n",
    "    \"Tell me about the new benefits enrollment\",\n",
    "    \"What was the feedback from the client presentation?\",\n",
    "    \"Is there a bug in the login page?\",\n",
    "    \"What are the next steps for the project?\",\n",
    "    \"When is the quarterly budget review?\",\n",
    "    \"What's the invoice amount due?\",\n",
    "    \"What new features are customers requesting?\",\n",
    "    \"When is the team lunch scheduled?\"\n",
    "]\n",
    "\n",
    "# Measure search performance\n",
    "search_times = []\n",
    "for query in tqdm(evaluation_queries, desc=\"Evaluating search performance\"):\n",
    "    start_time = time.time()\n",
    "    results = similarity_search.search(query, k=3)\n",
    "    end_time = time.time()\n",
    "    search_times.append((end_time - start_time) * 1000)  # Convert to milliseconds\n",
    "\n",
    "# Measure response generation performance\n",
    "response_times = []\n",
    "for query in tqdm(evaluation_queries, desc=\"Evaluating response generation\"):\n",
    "    results = similarity_search.search(query, k=3)\n",
    "    start_time = time.time()\n",
    "    response = response_generator.generate_response(results, query)\n",
    "    end_time = time.time()\n",
    "    response_times.append(end_time - start_time)  # In seconds\n",
    "\n",
    "# Display performance metrics\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Average search time: {np.mean(search_times):.2f} ms\")\n",
    "print(f\"Min search time: {np.min(search_times):.2f} ms\")\n",
    "print(f\"Max search time: {np.max(search_times):.2f} ms\")\n",
    "print(f\"\\nAverage response generation time: {np.mean(response_times):.2f} seconds\")\n",
    "print(f\"Min response generation time: {np.min(response_times):.2f} seconds\")\n",
    "print(f\"Max response generation time: {np.max(response_times):.2f} seconds\")\n",
    "\n",
    "# Visualize performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(search_times)), search_times)\n",
    "plt.title('Search Time by Query')\n",
    "plt.xlabel('Query Index')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(response_times)), response_times)\n",
    "plt.title('Response Generation Time by Query')\n",
    "plt.xlabel('Query Index')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. End-to-End Testing\n",
    "\n",
    "Let's perform an end-to-end test of our Email Wizard Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def query_email_wizard(query):\n",
    "    \"\"\"End-to-end function to query the Email Wizard Assistant.\"\"\"\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    # Record start time\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # Step 1: Search for relevant emails\n",
    "    search_start_time = time.time()\n",
    "    retrieved_emails = similarity_search.search(query, k=3)\n",
    "    search_end_time = time.time()\n",
    "    \n",
    "    # Step 2: Generate response\n",
    "    generation_start_time = time.time()\n",
    "    response = response_generator.generate_response(retrieved_emails, query)\n",
    "    generation_end_time = time.time()\n",
    "    \n",
    "    # Calculate timings\n",
    "    total_end_time = time.time()\n",
    "    search_time = search_end_time - search_start_time\n",
    "    generation_time = generation_end_time - generation_start_time\n",
    "    total_time = total_end_time - total_start_time\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nRetrieved Emails:\")\n",
    "    for i, email in enumerate(retrieved_emails):\n",
    "        print(f\"Email {i+1}: {email['subject']} (Similarity: {email['similarity']:.4f})\")\n",
    "    \n",
    "    print(\"\\nGenerated Response:\")\n",
    "    print(response)\n",
    "    \n",
    "    print(\"\\nPerformance:\")\n",
    "    print(f\"Search time: {search_time*1000:.2f} ms\")\n",
    "    print(f\"Response generation time: {generation_time:.2f} seconds\")\n",
    "    print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"retrieved_emails\": retrieved_emails,\n",
    "        \"performance\": {\n",
    "            \"search_time_ms\": search_time*1000,\n",
    "            \"generation_time_sec\": generation_time,\n",
    "            \"total_time_sec\": total_time\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with a few user queries\n",
    "user_queries = [\n",
    "    \"What's the status of our project?\",\n",
    "    \"When is the next team meeting scheduled?\",\n",
    "    \"What are the details of the server maintenance?\"\n",
    "]\n",
    "\n",
    "for query in user_queries:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    result = query_email_wizard(query)\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've implemented an Email Wizard Assistant using a Retrieval-Augmented Generation (RAG) model. The assistant can:\n",
    "\n",
    "1. Embed emails into vector representations\n",
    "2. Retrieve relevant emails based on user queries\n",
    "3. Generate coherent responses based on the retrieved emails\n",
    "\n",
    "The implementation demonstrates good performance in terms of search speed and response quality. The Flask API implementation in the `/api` directory provides a web interface for interacting with the assistant.\n",
    "\n",
    "Future improvements could include:\n",
    "- Using more advanced embedding models\n",
    "- Implementing Approximate Nearest Neighbors for better search performance\n",
    "- Adding more sophisticated response generation techniques\n",
    "- Expanding the email dataset for better coverage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
